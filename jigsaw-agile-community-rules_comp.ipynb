{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"},{"sourceId":426330,"sourceType":"modelInstanceVersion","modelInstanceId":347541,"modelId":368803}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%writefile constants.py\n\nCOMPLETE = \"Answer:\"\nprompt = f\"You are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule. Answer 'yes' or 'no' only.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T14:32:25.780395Z","iopub.execute_input":"2025-09-25T14:32:25.780738Z","iopub.status.idle":"2025-09-25T14:32:25.788714Z","shell.execute_reply.started":"2025-09-25T14:32:25.780706Z","shell.execute_reply":"2025-09-25T14:32:25.787725Z"}},"outputs":[{"name":"stdout","text":"Writing constants.py\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\n\ntrain_data = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/train.csv\")\nprint(len(train_data))\ntest_sample=    pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/test.csv\").sample(frac=0.5,random_state = 42 )\n\nprint(len(test_sample))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T14:32:27.387995Z","iopub.execute_input":"2025-09-25T14:32:27.388637Z","iopub.status.idle":"2025-09-25T14:32:27.854600Z","shell.execute_reply.started":"2025-09-25T14:32:27.388610Z","shell.execute_reply":"2025-09-25T14:32:27.853608Z"}},"outputs":[{"name":"stdout","text":"2029\n5\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-25T14:32:29.932032Z","iopub.execute_input":"2025-09-25T14:32:29.932387Z","iopub.status.idle":"2025-09-25T14:32:29.942016Z","shell.execute_reply.started":"2025-09-25T14:32:29.932361Z","shell.execute_reply":"2025-09-25T14:32:29.941009Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/jigsaw-agile-community-rules/sample_submission.csv\n/kaggle/input/jigsaw-agile-community-rules/train.csv\n/kaggle/input/jigsaw-agile-community-rules/test.csv\n/kaggle/input/qwen-3-embedding/transformers/0.6b/1/config.json\n/kaggle/input/qwen-3-embedding/transformers/0.6b/1/merges.txt\n/kaggle/input/qwen-3-embedding/transformers/0.6b/1/README.md\n/kaggle/input/qwen-3-embedding/transformers/0.6b/1/tokenizer.json\n/kaggle/input/qwen-3-embedding/transformers/0.6b/1/vocab.json\n/kaggle/input/qwen-3-embedding/transformers/0.6b/1/tokenizer_config.json\n/kaggle/input/qwen-3-embedding/transformers/0.6b/1/model.safetensors\n/kaggle/input/qwen-3-embedding/transformers/0.6b/1/generation_config.json\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install flash-attn --no-build-isolation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T12:49:15.406865Z","iopub.execute_input":"2025-09-25T12:49:15.407204Z","iopub.status.idle":"2025-09-25T12:51:51.257896Z","shell.execute_reply.started":"2025-09-25T12:49:15.407179Z","shell.execute_reply":"2025-09-25T12:51:51.255758Z"}},"outputs":[{"name":"stdout","text":"Collecting flash-attn\n  Downloading flash_attn-2.8.3.tar.gz (8.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.6.0+cu124)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->flash-attn)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->flash-attn)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->flash-attn)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->flash-attn)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->flash-attn)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->flash-attn)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch->flash-attn)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->flash-attn)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->flash-attn)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch->flash-attn)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: flash-attn\n  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for flash-attn: filename=flash_attn-2.8.3-cp311-cp311-linux_x86_64.whl size=256022485 sha256=0abc62d04f28f140f4f76ab7cfd1d8ce24a69c6ab0cbace8d4ab99640b68dc0a\n  Stored in directory: /root/.cache/pip/wheels/42/31/1f/4b22dd7295b3cb064b8fa9038f6d58fb15c9571555b2d7c39c\nSuccessfully built flash-attn\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, flash-attn\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed flash-attn-2.8.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import AutoTokenizer, AutoModel\nfrom torch import Tensor\nimport kagglehub\n\n\n# Pooling function (same as before)\ndef last_token_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n    # Check whether padding is on the left\n    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n    if left_padding:\n        return last_hidden_states[:, -1]\n    else:\n        sequence_lengths = attention_mask.sum(dim=1) - 1\n        batch_size = last_hidden_states.shape[0]\n        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n\n\n# OOP wrapper around tokenizer + model + pooling\nclass QwenEmbedder(nn.Module):\n    def __init__(self, model_dir: str, max_length: int = 8192, device: str = None):\n        super().__init__()\n        self.tokenizer = AutoTokenizer.from_pretrained(model_dir, padding_side=\"left\")\n        self.model = AutoModel.from_pretrained(model_dir)\n        self.max_length = max_length\n        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.to(self.device)  # move model to device\n\n    def forward(self, texts: list[str]) -> Tensor:\n        # Tokenize batch\n        batch_dict = self.tokenizer(\n            texts,\n            padding=True,\n            truncation=True,\n            max_length=self.max_length,\n            return_tensors=\"pt\",\n        ).to(self.device)\n\n        # Forward pass\n        outputs = self.model(**batch_dict)\n\n        # Pool to sequence embedding\n        embeddings = last_token_pool(outputs.last_hidden_state, batch_dict[\"attention_mask\"])\n\n        # Normalize embeddings\n        embeddings = F.normalize(embeddings, p=2, dim=1)\n        return embeddings\n\nif __name__ == \"__main__\":\n    model_dir = kagglehub.model_download(\"qwen-lm/qwen-3-embedding/transformers/0.6b\")\n    embedder = QwenEmbedder(model_dir)\n\n    # Queries and docs\n    queries = [\n        \"Instruct: Given a web search query, retrieve relevant passages that answer the query\\nQuery: What is the capital of China?\",\n        \"Instruct: Given a web search query, retrieve relevant passages that answer the query\\nQuery: Explain gravity\"\n    ]\n    documents = [\n        \"The capital of China is Beijing.\",\n        \"Gravity is a force that attracts two bodies towards each other...\"\n    ]\n\n    # Get embeddings\n    query_emb = embedder(queries)\n    doc_emb = embedder(documents)\n\n    # Compute similarity\n    scores = query_emb @ doc_emb.T\n    print(scores.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T14:32:37.512762Z","iopub.execute_input":"2025-09-25T14:32:37.513195Z","iopub.status.idle":"2025-09-25T14:33:26.755744Z","shell.execute_reply.started":"2025-09-25T14:32:37.513164Z","shell.execute_reply":"2025-09-25T14:33:26.754899Z"}},"outputs":[{"name":"stderr","text":"2025-09-25 14:33:01.525144: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758810781.783584      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758810781.858404      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"[[0.8712036609649658, 0.2468034327030182], [0.1934046745300293, 0.5418860912322998]]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"%%writefile utils.py\n\nimport pandas as pd \nfrom constants import prompt, COMPLETE\nimport numpy as np \nimport random\nimport re\nfrom datasets import Dataset\n\nrandom.seed(42)\nnp.random.seed(42)\n\ndef url_to_semantics(txt : str) -> str:\n    if not isinstance(txt,str):\n        return \"\"\n    url_pattern = r'https?://[^\\s/$.?#].[^\\s]*'\n    urls = re.findall(url_pattern, txt)\n    \n    if not urls:\n        return \"\" \n\n    all_semantics = []\n    seen_semantics = set()\n\n    for url in urls:\n        url_lower = url.lower()\n        \n        domain_match = re.search(r\"(?:https?://)?([a-z0-9\\-\\.]+)\\.[a-z]{2,}\", url_lower)\n        if domain_match:\n            full_domain = domain_match.group(1)\n            parts = full_domain.split('.')\n            for part in parts:\n                if part and part not in seen_semantics and len(part) > 3: # Avoid short parts like 'www'\n                    all_semantics.append(f\"domain:{part}\")\n                    seen_semantics.add(part)\n\n        # Extract path parts\n        path = re.sub(r\"^(?:https?://)?[a-z0-9\\.-]+\\.[a-z]{2,}/?\", \"\", url_lower)\n        path_parts = [p for p in re.split(r'[/_.-]+', path) if p and p.isalnum()] # Split by common delimiters\n\n        for part in path_parts:\n            # Clean up potential file extensions or query params\n            part_clean = re.sub(r\"\\.(html?|php|asp|jsp)$|#.*|\\?.*\", \"\", part)\n            if part_clean and part_clean not in seen_semantics and len(part_clean) > 3:\n                all_semantics.append(f\"path:{part_clean}\")\n                seen_semantics.add(part_clean)\n\n    if not all_semantics:\n        return \"\"\n\n    return f\"\\nURL Keywords: {' '.join(all_semantics)}\"\n\ndef build_prompt(row):\n    subreddit = row.get(\"subreddit\", \"unknown\")\n    rule = row.get(\"rule\", \"\")\n    pos_example = row.get(\"positive_example\", \"\")\n    neg_example = row.get(\"negative_example\", \"\")\n    body = row.get(\"body\", \"\")\n    url_features_body = url_to_semantics(body)\n    url_features_pos = url_to_semantics(pos_example)\n    url_features_neg = url_to_semantics(neg_example)\n    return f\"\"\"\n{prompt}\n\nr/{subreddit} \nrule: {rule}\nExamples : \n1) {pos_example}{url_features_pos}\n{COMPLETE} yes\n2) {neg_example}{url_features_neg}\n{COMPLETE} no\n\n------\nComment: {body}{url_features_body}\n{COMPLETE} \"\"\"\n\n\ndef get_data_for_training(fpath,sample_frac = 0.5):\n    train_data = pd.read_csv(f\"{fpath}/train.csv\")\n    \n    test_df= pd.read_csv(f\"{fpath}/test.csv\").sample(frac=sample_frac,random_state = 42 )\n\n    \n\n\n    train_df = train_data[['body','rule','subreddit','positive_example_1','positive_example_2', 'negative_example_1','negative_example_2','rule_violation']]\n    \n    #randomly assign examples\n    train_df['positive_example'] = np.where(np.random.rand(len(train_df)) <0.5 , train_df['positive_example_1'],train_df['positive_example_2'])\n    train_df['negative_example'] = np.where(np.random.rand(len(train_df)) <0.5 , train_df['negative_example_1'], train_df['negative_example_2'])\n    train_df.drop(columns = ['positive_example_1','positive_example_2', 'negative_example_1','negative_example_2'], inplace = True)\n\n    dfs = [train_df]\n    \n    # build test df \n    \n    for rule_violation in ['yes', 'no']:\n        for i in range(1,3): #loop through both examples\n            subdf =  test_df.copy().drop(columns=['body','positive_example_1','positive_example_2', 'negative_example_1','negative_example_2'])\n\n            if rule_violation == 'yes':   # case when rule is violated \n                subdf['body'] = test_df[f'positive_example_{i}']\n                subdf['positive_example'] = test_df[f'positive_example_{3-i}']\n                subdf['negative_example'] = np.where(np.random.rand(len(test_df))<0.5, test_df[f'negative_example_{i}'],test_df[f'negative_example_{3-i}'])\n                subdf['rule_violation'] = 1\n            else:  # case when rule is not violated \n                subdf['body'] = test_df[f'negative_example_{i}']\n                subdf['positive_example'] = np.where(np.random.rand(len(test_df))<0.5, test_df[f'positive_example_{i}'],test_df[f'positive_example_{3-i}'])\n\n                subdf['neagtive_example'] = test_df[f'negative_example_{3-i}']\n                subdf['rule_violation'] = 0\n            dfs.append(subdf)\n\n    df =  pd.concat(dfs, axis = 0).drop_duplicates(ignore_index = True)\n    \n    return df\n\ndef build_dataset(df):\n    df['prompt'] = df.apply(build_prompt, axis = 1)\n\n    df['completion'] = df['rule_violation'].map(\n        {\n            1 : 'yes',\n            0 : 'no'\n        }\n    )\n    df = df[['prompt','completion']]\n\n    print(df)\n\n    dataset = Dataset.from_pandas(df)\n    dataset.to_pandas().to_csv(\"/kaggle/working/dataset.csv\", index=False)\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T14:33:26.757298Z","iopub.execute_input":"2025-09-25T14:33:26.758083Z","iopub.status.idle":"2025-09-25T14:33:26.767416Z","shell.execute_reply.started":"2025-09-25T14:33:26.758051Z","shell.execute_reply":"2025-09-25T14:33:26.766485Z"}},"outputs":[{"name":"stdout","text":"Overwriting utils.py\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"%%writefile train.py\nimport pandas as pd\nimport numpy as np\nfrom IPython.display import display, HTML\nfrom utils import get_data_for_training, build_dataset, build_prompt, url_to_semantics\n\n# Lora imports\nfrom trl import SFTTrainer, SFTConfig\nfrom peft import LoraConfig\nfrom tqdm.auto import tqdm\nfrom transformers.utils import is_torch_bf16_gpu_available\n#from constants import DATA_PATH, BASE_MODEL_PATH, LORA_PATH\n\n\ndef main():\n    data_path = \"/kaggle/input/jigsaw-agile-community-rules/\"\n    df = get_data_for_training(data_path)\n    train_dataset = build_dataset(df)\n    df_train = pd.DataFrame(train_dataset)\n\n    df_train = pd.DataFrame(train_dataset)\n    print(pd.read_csv('/kaggle/working/dataset.csv'))\n    \n    #print(df_train.head(10))\n    \n\nif __name__ == \"__main__\":\n    main()\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T14:33:40.344621Z","iopub.execute_input":"2025-09-25T14:33:40.345033Z","iopub.status.idle":"2025-09-25T14:33:40.352003Z","shell.execute_reply.started":"2025-09-25T14:33:40.345000Z","shell.execute_reply":"2025-09-25T14:33:40.350855Z"}},"outputs":[{"name":"stdout","text":"Overwriting train.py\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"%%writefile inference.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T12:52:48.937851Z","iopub.execute_input":"2025-09-25T12:52:48.938343Z","iopub.status.idle":"2025-09-25T12:52:48.960626Z","shell.execute_reply.started":"2025-09-25T12:52:48.938307Z","shell.execute_reply":"2025-09-25T12:52:48.958981Z"}},"outputs":[{"name":"stderr","text":"UsageError: %%writefile is a cell magic, but the cell body is empty.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!python train.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T14:33:46.326109Z","iopub.execute_input":"2025-09-25T14:33:46.327156Z","iopub.status.idle":"2025-09-25T14:33:49.864041Z","shell.execute_reply.started":"2025-09-25T14:33:46.327111Z","shell.execute_reply":"2025-09-25T14:33:49.862745Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"                                                 prompt completion\n0     \\nYou are given a comment from reddit and a ru...         no\n1     \\nYou are given a comment from reddit and a ru...         no\n2     \\nYou are given a comment from reddit and a ru...        yes\n3     \\nYou are given a comment from reddit and a ru...        yes\n4     \\nYou are given a comment from reddit and a ru...        yes\n...                                                 ...        ...\n2044  \\nYou are given a comment from reddit and a ru...         no\n2045  \\nYou are given a comment from reddit and a ru...         no\n2046  \\nYou are given a comment from reddit and a ru...         no\n2047  \\nYou are given a comment from reddit and a ru...         no\n2048  \\nYou are given a comment from reddit and a ru...         no\n\n[2049 rows x 2 columns]\n                                                 prompt completion\n0     \\nYou are given a comment from reddit and a ru...         no\n1     \\nYou are given a comment from reddit and a ru...         no\n2     \\nYou are given a comment from reddit and a ru...        yes\n3     \\nYou are given a comment from reddit and a ru...        yes\n4     \\nYou are given a comment from reddit and a ru...        yes\n...                                                 ...        ...\n2044  \\nYou are given a comment from reddit and a ru...         no\n2045  \\nYou are given a comment from reddit and a ru...         no\n2046  \\nYou are given a comment from reddit and a ru...         no\n2047  \\nYou are given a comment from reddit and a ru...         no\n2048  \\nYou are given a comment from reddit and a ru...         no\n\n[2049 rows x 2 columns]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}